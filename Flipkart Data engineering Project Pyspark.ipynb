#imports 
from pyspark.sql.functions import col,isnan,when,count
from pyspark.sql.functions import expr
from pyspark.sql.functions import *

#Setting up the enviorment
from pyspark.sql import SparkSession

spark=SparkSession.builder.appName("flipkart data engineering").getOrCreate()


#load the CSV data
file_path='/FileStore/tables/test.csv'

flipkart_df=spark.read.csv(file_path,header=True,inferSchema=True)

flipkart_df.display()


#checking the Schema

flipkart_df.printSchema()


# handling the missing the data
flipkart_df.select([count(when(col(c).isNull(), c)).alias(c) for c in flipkart_df.columns]).display()

#drop missing values
flipkart_df_clean=flipkart_df.dropna()

#filling specific values to the nan columns or missing columns
flipkart_df_filled=flipkart_df.fillna({"Rating":0,"maincateg": 0})


#Data tranformation

#calculate the effective price after discount
flipkart_df_transformed=flipkart_df.withColumn("EffectivePrice", expr("Price - (Price * Discount / 100)"))

#show the  updated Dataframe
flipkart_df_transformed.select("ProductName","Price", "Discount","EffectivePrice").display(5)

#filter products with  ratings greater than 4 and priced below 10000
high_rated_products = flipkart_df_filled.filter((col("Rating") > 4))

# Show the result
high_rated_products.display(5)

#group the category and calculate average rating

avg_rating_by_category=flipkart_df_filled.groupBy("maincateg").avg("Rating")
avg_rating_by_category.display()

#Total Revenue from category
total_Revenue_by_category=flipkart_df_filled.groupBy("maincateg").agg(sum("Rating"))
total_Revenue_by_category.display()

# saved the proceesed data
output_table='flipkart_data_analysis_table'
flipkart_df_filled.write.mode("overwrite").saveAsTable(output_table)

%sql
select * from flipkart_data_analysis_table limit 20
